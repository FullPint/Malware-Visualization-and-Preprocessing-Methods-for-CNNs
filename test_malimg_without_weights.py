# Standard Library Imports
import glob
import os

# External Libray Importsj
import comet_ml
from comet_ml import Experiment

from keras.applications.vgg16 import VGG16
from keras.preprocessing.image import ImageDataGenerator
from keras import optimizers
from keras.layers import Input, Flatten, Dense
from keras.models import Model
from keras.utils import multi_gpu_model
from keras.callbacks import EarlyStopping, ModelCheckpoint

import numpy as np
import pandas as pd


# User Defined Imports

# User Defined Constants
MALIMG_PATH = "/project/verma/alec/Malware-Visualization-and-Preprocessing-Methods-for-CNNs/data-sets/malimg_paper_dataset_imgs"
SAVE_MODEL_PATH = (
    "/project/verma/alec/vgg-16-play/saved-models/vgg_16_with_weights_on_malimg.h5"
)
SAVE_HISTORY_JSON_PATH = (
    "/project/verma/alec/vgg-16-play/saved-models/vgg_16_with_weights_on_malimg.json"
)
SAVE_HISTORY_CSV_PATH = (
    "/project/verma/alec/vgg-16-play/saved-models/vgg_16_with_weights_on_malimg.csv"
)
DEFAULT_BATCH = 6
DEFUALT_EPOCH = 25

experiment = Experiment(
    api_key="rYeQ6zONJUHPsyCB55gZKxu1x",
    project_name="malware-visualization-cnns",
    workspace="fullpint",
)


def get_image_paths_dirs(data_dir):
    return glob.glob(data_dir + "/*")


def get_images_paths(image_dirs):
    return glob.glob(image_dirs + "/*.png")


def get_plain_data_gen():
    return ImageDataGenerator(validation_split=0.2)


def get_train_validation_flows(img_gen):
    return (
        img_gen.flow_from_directory(MALIMG_PATH, subset="training"),
        img_gen.flow_from_directory(MALIMG_PATH, subset="validation"),
    )


def build_model(out_dim):

    # Get back the convolutional part of a VGG network trained on ImageNet
    model_vgg16_conv = VGG16(weights=None, include_top=False)
    model_vgg16_conv.summary()

    # Creating New Input
    input = Input(shape=(256, 256, 3), name="mal_img_input")

    # Using Generated Model
    output_vgg16_conv = model_vgg16_conv(input)

    # Add the fully-connected layers
    x = Flatten(name="flatten")(output_vgg16_conv)
    x = Dense(4096, activation="relu", name="fc1")(x)
    x = Dense(4096, activation="relu", name="fc2")(x)
    x = Dense(out_dim, activation="softmax", name="mal_img_predict")(x)

    return multi_gpu_model(Model(inputs=input, outputs=x), gpus=2)


def compile_model(model):
    model.compile(
        optimizer=optimizers.SGD(),
        loss="categorical_crossentropy",
        metrics=["accuracy", "categorical_accuracy"],
    )


def get_callbacks():
    early_stopping = EarlyStopping(
        monitor="val_loss", min_delta=1, mode="min", verbose=1, patience=10
    )
    model_checkpoint = ModelCheckpoint(
        "SAVE_MODEL_PATH",
        monitor="val_accuracy",
        mode="max",
        verbose=1,
        save_best_only=True,
    )
    return [early_stopping, model_checkpoint]


def train_model(model, train, val):
    number_of_samples = len(get_image_paths_dirs(MALIMG_PATH))

    print("Training...")
    return model.fit_generator(
        generator=train,
        steps_per_epoch=train.samples // DEFAULT_BATCH,
        validation_data=val,
        validation_steps=train.samples // DEFAULT_BATCH,
        epochs=DEFUALT_EPOCH,
        callbacks=get_callbacks(),
    )


def evaluate_model(model, generator, x_train):
    print("Evaluating...")
    return model.evaluate_generator(
        generator, steps=(len(x_train) / 32), epochs=DEFUALT_EPOCH
    )


def save_model_history(history):
    hist_df = pd.DataFrame(history.history)

    with open(SAVE_HISTORY_JSON_PATH, mode="w+") as f:
        hist_df.to_json(f)

    with open(SAVE_HISTORY_CSV_PATH, mode="w+") as f:
        hist_df.to_csv(f)


def main():

    img_path_dirs = get_image_paths_dirs(MALIMG_PATH)
    my_model = build_model(len(img_path_dirs) - 1)
    compile_model(my_model)
    my_generator = get_plain_data_gen()
    my_train, my_val = get_train_validation_flows(my_generator)
    print(my_model.summary())

    history = train_model(my_model, my_train, my_val)

    my_model.save(SAVE_MODEL_PATH)
    save_model_history(history)

    project_dir = os.getcwd()
    experiment.log_asset(file_data=os.path.join(project_dir, SAVE_HISTORY_JSON_PATH))
    experiment.log_asset(file_data=os.path.join(project_dir, SAVE_HISTORY_CSV_PATH))
    experiment.log_asset(file_data=os.path.join(project_dir, SAVE_MODEL_PATH))

    score, acc = evaluate_model(my_model, my_generator, my_train[0])
    print("Test score:", score)
    print("Test accuracy:", acc)


if __name__ == "__main__":
    main()
